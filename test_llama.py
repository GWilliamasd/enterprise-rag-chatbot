import requests
import json

def test_ollama():
    """æµ‹è¯•Ollamaå’Œllama3.1æ˜¯å¦å¯ç”¨"""
    print("ğŸ” æµ‹è¯•OllamaæœåŠ¡...")
    
    # æµ‹è¯•OllamaæœåŠ¡æ˜¯å¦è¿è¡Œ
    try:
        response = requests.get("http://localhost:11434/api/version", timeout=5)
        if response.status_code == 200:
            print("âœ… OllamaæœåŠ¡æ­£åœ¨è¿è¡Œ")
            version_info = response.json()
            print(f"ç‰ˆæœ¬: {version_info.get('version', 'Unknown')}")
        else:
            print("âŒ OllamaæœåŠ¡æ— å“åº”")
            return False
    except Exception as e:
        print(f"âŒ æ— æ³•è¿æ¥OllamaæœåŠ¡: {e}")
        print("è¯·ç¡®ä¿è¿è¡Œ: ollama serve")
        return False
    
    # æµ‹è¯•llama3.1æ¨¡å‹
    print("\nğŸ¤– æµ‹è¯•llama3.1æ¨¡å‹...")
    try:
        data = {
            "model": "qwen3:4b",
            "prompt": "ä½ å¥½ï¼Œè¯·å›å¤ä¸€ä¸ªå­—ï¼šå¥½",
            "stream": False
        }
        
        response = requests.post(
            "http://localhost:11434/api/generate",
            json=data,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            reply = result.get("response", "").strip()
            print(f"âœ… llama3.1æ¨¡å‹å·¥ä½œæ­£å¸¸")
            print(f"å›å¤: {reply}")
            return True
        else:
            print(f"âŒ llama3.1æ¨¡å‹è¯·æ±‚å¤±è´¥: {response.status_code}")
            print(f"é”™è¯¯: {response.text}")
            return False
            
    except Exception as e:
        print(f"âŒ llama3.1æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    success = test_ollama()
    if success:
        print("\nğŸ‰ llama3.1å¯ä»¥æ­£å¸¸ä½¿ç”¨ï¼")
    else:
        print("\nâŒ llama3.1ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥Ollamaè®¾ç½®")